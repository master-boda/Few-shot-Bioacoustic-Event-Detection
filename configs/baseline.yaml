# Paths
data_root: "data/raw"
train_metadata: "data/metadata/train.csv"
val_metadata: "data/metadata/val.csv"
work_dir: "experiments/baseline"

# Dataset / episodes
sample_rate: 32000
clip_duration: 5.0  # seconds
n_way: 3        # reduced to match available classes
k_shot: 1       # min clips per class in train: BV/HT (5), MT (2), WMW (161)
query_per_class: 1
episodes_per_epoch: 100
val_episodes: 50
window_seconds: 1.0
hop_seconds: 0.25

# Features
features:
  n_mels: 64
  n_fft: 1024
  hop_length: 320
  f_min: 50
  f_max: 14000
  use_spectral_contrast: true
  spectral_contrast_bands: 6

# Post-processing (few-shot detection)
postprocess:
  threshold: 0.0           # used when threshold_mode=global
  threshold_mode: "percentile"
  percentile: 99.5
  zscore: 2.5
  median_filter: 3         # frames (odd int), 0 to disable
  min_duration: 0.2        # seconds, drop shorter events (merge mode)
  merge_gap: 0.0           # seconds, merge gaps shorter than this
  event_mode: "peak"       # peak or merge
  peak_distance: 0.25      # seconds between peaks
  event_duration: 0.0      # 0 uses mean support duration
  score_mode: "pos_minus_bg"
  bg_percentile: 10.0

# Model
model:
  name: "prototypical"
  hidden_size: 64
  embedding_dim: 128
  num_blocks: 3
  channel_mult: 2

# Optimization
optimizer:
  name: "adam"
  lr: 0.001
  weight_decay: 0.0
scheduler:
  name: "step"
  step_size: 20
  gamma: 0.5

# Training
epochs: 50
episodes_per_epoch: 100
val_episodes: 50
num_workers: 20
seed: 42

# Per-file training (train_events.py)
train_events:
  pos_iou: 0.3
  neg_iou: 0.05
  proto_weight: 1.0
  bce_weight: 1.0
  class_strategy: "max_pos"
